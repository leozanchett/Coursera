{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Ordinary Least Squares (OLS) ou Mínimos Quadrados Ordinários é um método de estimação de parâmetros em modelos de regressão linear. Em contraste com os métodos de regularização discutidos anteriormente (Lasso e Ridge), a OLS busca minimizar a soma dos quadrados dos resíduos (erros) diretamente, sem adicionar termos de penalidade.\n",
    "\n",
    "Para um modelo de regressão linear simples, a OLS busca encontrar os coeficientes \\(\\beta_0\\) (intercepto) e \\(\\beta_1\\) (inclinação) que minimizam a seguinte função de custo:\n",
    "\n",
    "\\[ \\text{Função de Custo OLS} = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 \\cdot x_i))^2 \\]\n",
    "\n",
    "Onde:\n",
    "- \\(n\\) é o número de observações no conjunto de dados.\n",
    "- \\(y_i\\) é o valor observado da variável dependente para a observação \\(i\\).\n",
    "- \\(x_i\\) é o valor da variável independente para a observação \\(i\\).\n",
    "- \\(\\beta_0\\) é o intercepto.\n",
    "- \\(\\beta_1\\) é o coeficiente associado à variável independente.\n",
    "\n",
    "Os coeficientes que minimizam a soma dos quadrados dos resíduos podem ser encontrados analiticamente através de equações normais ou numericamente por métodos de otimização, como o Gradiente Descendente.\n",
    "\n",
    "A OLS é um método amplamente utilizado quando a multicolinearidade não é um problema significativo e não há razão para aplicar regularização. No entanto, em situações onde há multicolinearidade ou o número de características é grande, métodos de regularização como Lasso ou Ridge podem ser preferíveis, pois ajudam a evitar overfitting e podem levar a modelos mais estáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])\n",
    "reg.coef_\n",
    "\n",
    "# array([0.5, 0.5]) o resultado [0.5, 0.5] indica que o modelo treinado atribui um peso de 0.5 a cada uma das características. \n",
    "# Em outras palavras, o modelo aprendeu uma relação linear simples onde a soma ponderada das características é igual ao valor alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Ridge regression and classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Ridge Regression (também conhecida como regressão Ridge) e a Ridge Classification (regressão Ridge para problemas de classificação) são métodos que utilizam regularização L2. A regularização L2 adiciona um termo à função de custo do modelo proporcional à soma dos quadrados dos coeficientes. Assim como o Lasso (que utiliza a regularização L1), a Ridge Regression visa evitar overfitting e lidar com a multicolinearidade, mas de uma maneira um pouco diferente.\n",
    "\n",
    "### Ridge Regression (Regressão Ridge):\n",
    "\n",
    "A Ridge Regression é usada em problemas de regressão linear. A função de custo da Ridge Regression é dada por:\n",
    "\n",
    "\\[ \\text{Função de Custo} = \\text{Soma dos Quadrados dos Resíduos} + \\alpha \\times \\text{Soma dos Quadrados dos Coeficientes} \\]\n",
    "\n",
    "Onde:\n",
    "- A \"Soma dos Quadrados dos Resíduos\" é a mesma que na regressão linear comum.\n",
    "- A segunda parte, \\(\\alpha \\times \\text{Soma dos Quadrados dos Coeficientes}\\), é o termo de regularização L2, onde \\(\\alpha\\) controla a força da penalização.\n",
    "\n",
    "A Ridge Regression é útil quando há multicolinearidade (alta correlação) entre as características, pois ela suaviza os coeficientes, impedindo que se tornem muito grandes. Ela não tende a zerar completamente os coeficientes como o Lasso faz.\n",
    "\n",
    "### Ridge Classification (Regressão Ridge para Classificação):\n",
    "\n",
    "A ideia da Ridge Regression pode ser estendida para problemas de classificação, resultando em Ridge Classification. Aqui, você pode usar a regularização L2 em algoritmos de classificação, como a Regressão Logística.\n",
    "\n",
    "A função de custo para Ridge Classification seria semelhante à da Ridge Regression, mas aplicada a um problema de classificação. O objetivo é minimizar a soma dos quadrados dos resíduos (ou log-verossimilhança no caso da Regressão Logística) e, ao mesmo tempo, penalizar os coeficientes.\n",
    "\n",
    "Em resumo, tanto a Ridge Regression quanto a Ridge Classification utilizam a regularização L2 para evitar overfitting e lidar com multicolinearidade. A escolha entre Ridge e Lasso (que utiliza a regularização L1) muitas vezes depende das características específicas do conjunto de dados e dos requisitos do problema. Ambas as técnicas são ferramentas valiosas em estatística e aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34545455 0.34545455]\n",
      "0.13636363636363638\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha=.5) #  O parâmetro alpha é o hiperparâmetro de regularização, controlando a força da penalização. Valores maiores de alpha resultam em uma penalização mais forte.\n",
    "reg.fit([[0, 0], [0, 0], [1, 1]], [0, .1, 1])\n",
    "print(reg.coef_) # Retorna os coeficientes (ou pesos) associados às características após o treinamento do modelo. No caso do Ridge, esses coeficientes são penalizados para evitar valores muito grandes.\n",
    "print(reg.intercept_) # Retorna o termo de interceptação (também chamado de viés) associado ao modelo. O termo de interceptação em um modelo linear é o valor esperado de y quando todos os recursos são iguais a zero.\n",
    "\n",
    "# Note que a regularização Ridge adiciona um termo de penalização à função de custo, que é controlado pelo parâmetro alpha. \n",
    "# Isso ajuda a evitar overfitting, especialmente quando há multicolinearidade nas características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.4. Definindo o parâmetro de regularização: deixar um de fora Validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13)) # O RidgeCV executa a validação cruzada internamente para escolher o valor de alpha que melhor generaliza os dados fornecidos.\n",
    "reg.fit([[0, 0], [0, 0], [1, 1]], [0, .1, 1]) # O parâmetro alphas é uma lista de valores para testar. Se nenhum valor for fornecido, o objeto usará os valores padrão de np.logspace (-10, 10, 20), ou seja, os valores de alfa serão escolhidos automaticamente.\n",
    "reg.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-06 2.15443469e-05 4.64158883e-04 1.00000000e-02\n",
      " 2.15443469e-01 4.64158883e+00 1.00000000e+02 2.15443469e+03\n",
      " 4.64158883e+04 1.00000000e+06]\n",
      "[1.e-06 1.e+00 1.e+06]\n"
     ]
    }
   ],
   "source": [
    "print(np.logspace(-6, 6, 10))\n",
    "print(np.logspace(-6, 6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO (Least Absolute Shrinkage and Selection Operator) é um método de regularização usado em modelos de regressão linear. A técnica Lasso adiciona uma penalidade à função de custo do modelo, que é proporcional à soma dos valores absolutos dos coeficientes.\n",
    "\n",
    "Em termos simples, o Lasso tenta minimizar a soma dos quadrados dos resíduos da regressão, da mesma forma que a regressão linear comum, mas com a adição de um termo de penalidade proporcional à soma dos valores absolutos dos coeficientes. A função de custo (ou função objetivo) da regressão Lasso é dada por:\n",
    "\n",
    "\\[ \\text{Função de Custo} = \\text{Soma dos Quadrados dos Resíduos} + \\alpha \\times \\text{Soma dos Valores Absolutos dos Coeficientes} \\]\n",
    "\n",
    "O parâmetro \\(\\alpha\\) (alfa) controla a força da penalização. Quanto maior o valor de \\(\\alpha\\), mais forte é a penalização, e mais coeficientes são levados a zero. Isso faz com que o Lasso tenha a capacidade de realizar seleção de características, eliminando algumas das características menos importantes do modelo.\n",
    "\n",
    "A principal vantagem do Lasso é a capacidade de lidar com conjuntos de dados com multicolinearidade (correlações elevadas entre características), eliminando algumas características e selecionando automaticamente as mais relevantes para a predição. Isso pode ser útil para evitar overfitting e simplificar modelos.\n",
    "\n",
    "Em resumo, o Lasso é uma técnica de regularização que combina a regressão linear com a penalização dos coeficientes através da norma L1 (soma dos valores absolutos). Essa técnica é amplamente utilizada em problemas de regressão quando se deseja realizar seleção automática de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8]\n",
      "[0.6 0. ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model  # Importa o módulo de modelos lineares do sklearn\n",
    "reg = linear_model.Lasso(alpha=0.1)  # Cria um objeto de regressão Lasso. O parâmetro alpha é o parâmetro de regularização que controla a complexidade do modelo.\n",
    "reg.fit([[0, 0], [1, 1]], [0, 1])  # Treina o modelo com os dados de entrada [[0, 0], [1, 1]] e os correspondentes valores de saída [0, 1]\n",
    "print(reg.predict([[1, 1]]))  # Usa o modelo treinado para prever a saída para a entrada [1, 1]\n",
    "print(reg.coef_)  # Retorna os coeficientes (ou pesos) associados às características após o treinamento do modelo. No caso do Lasso, esses coeficientes podem ser zero, o que significa que algumas características são ignoradas pelo modelo.\n",
    "# O modelo Lasso é um tipo de regressão linear que usa a regularização L1. Isso significa que ele tenta minimizar a soma dos valores \n",
    "# absolutos dos coeficientes (multiplicada pelo parâmetro de regularização alpha). \n",
    "# Isso pode levar a alguns coeficientes se tornarem exatamente zero, o que é uma forma de seleção automática de recursos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.10. Regressão Bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Regressão Bayesiana é um método de modelagem estatística que incorpora conceitos da teoria de probabilidade bayesiana para fazer inferências sobre os parâmetros de um modelo. Diferentemente da abordagem frequentista, que considera os parâmetros como fixos e desconhecidos, a abordagem bayesiana trata os parâmetros como variáveis aleatórias e modela a distribuição de probabilidade a posteriori desses parâmetros.\n",
    "\n",
    "Na Regressão Bayesiana, assume-se uma distribuição a priori para os parâmetros do modelo, representando o conhecimento ou crenças iniciais sobre esses parâmetros antes de observar os dados. Com a adição dos dados observados, a distribuição a posteriori é calculada usando o teorema de Bayes, fornecendo uma atualização das crenças sobre os parâmetros do modelo.\n",
    "\n",
    "A principal vantagem da Regressão Bayesiana é sua capacidade de lidar com incertezas de forma natural, fornecendo distribuições de probabilidade para os parâmetros em vez de estimativas pontuais. Isso é particularmente útil em situações com conjuntos de dados pequenos ou quando a incerteza nos parâmetros é uma consideração importante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesianRidge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;BayesianRidge<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.BayesianRidge.html\">?<span>Documentation for BayesianRidge</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>BayesianRidge()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "BayesianRidge()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "X = [[0., 0.], [1., 1.], [2., 2.], [3., 3.]]\n",
    "Y = [0., 1., 2., 3.]\n",
    "reg = linear_model.BayesianRidge()\n",
    "reg.fit(X, Y)\n",
    "linear_model.BayesianRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99999887]\n",
      "[0.49999993 0.49999993]\n"
     ]
    }
   ],
   "source": [
    "print(reg.predict([[10., 10.]]))\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a regressão Bayesiana Ridge é mais robusto para problemas mal colocados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
